{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22163fc5",
   "metadata": {},
   "source": [
    "# Model Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d68cc4",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde7c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import optuna\n",
    "import random\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.trial import TrialState\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Optional, Union, Any, Dict\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from transformers import (AutoTokenizer, TFAutoModel, pipeline, MarianMTModel, MarianTokenizer,\n",
    "                         AutoModelForSequenceClassification, TrainingArguments, Trainer,\n",
    "                         AutoModelForMaskedLM, EarlyStoppingCallback)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, multilabel_confusion_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf87f4",
   "metadata": {},
   "source": [
    "## Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bac50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "model_path = os.path.abspath(os.path.join(cwd, \"..\", \"part_3\", \"final_model\"))\n",
    "\n",
    "model100 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model100.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066683f",
   "metadata": {},
   "source": [
    "## a) Distill/Quantize your best-performing model into a lighter model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b78169",
   "metadata": {},
   "source": [
    "We will use Dynamic quantization where weights are quantized and stored in int8, and there is no need to retrain the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13601e49",
   "metadata": {},
   "source": [
    "To do this we will use the official PyTorch quantization toolkit: torch.quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72a6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model100, \n",
    "    {torch.nn.Linear},  # Only quantize Linear layers\n",
    "    dtype=torch.qint8 #converting from 32-bit-float to 8-bit integer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6517943",
   "metadata": {},
   "source": [
    "We only quantize the linear layers of the model as these are the most compute-heavy layers in BERT-like models. Model quantization will specially benefit users running the model on a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb0698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative path using pathlib\n",
    "quantized_model_path = Path(\"quantized_model\") / \"pytorch_model.bin\"\n",
    "\n",
    "# Save the quantized model's state dict\n",
    "torch.save(quantized_model.state_dict(), quantized_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72640fa4",
   "metadata": {},
   "source": [
    "## b) Performance and Speed Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449dc47e",
   "metadata": {},
   "source": [
    "Defining tokenizer and global random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6708d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seeds to all the processes\n",
    "def set_global_seeds(seed=42):\n",
    "    # Python\n",
    "    random.seed(seed)\n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    # to have compatibiliy with GPU\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_global_seeds(42)\n",
    "seed=42\n",
    "\n",
    "model_ckpt   = \"distilbert/distilbert-base-uncased\"\n",
    "num_labels   = 5\n",
    "max_length   = 128                   # truncate / pad length\n",
    "batch_size   = 16\n",
    "\n",
    "# Define Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "def tokenize(batch):\n",
    "    tokenized = tok(\n",
    "        batch[\"comment_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    tokenized[\"labels\"] = [\n",
    "        [float(batch[label][i]) for label in labels]\n",
    "        for i in range(len(batch[\"comment_text\"]))\n",
    "    ]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d4c61",
   "metadata": {},
   "source": [
    "Importing data to test the speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "489a93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "df = load_dataset(\"Arsive/toxicity_classification_jigsaw\")\n",
    "val = df[\"validation\"].to_pandas()\n",
    "val = val.drop(columns=[\"threat\"])\n",
    "# Preserve original metadata (comment_text and id) we will use it for later comparison\n",
    "val_metadata = val[[\"comment_text\"]].copy()\n",
    "val_metadata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = df[\"train\"].to_pandas()\n",
    "train = train.drop(columns=[\"threat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f806e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6490/6490 [00:00<00:00, 11760.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "labels= [\"toxic\", \"severe_toxic\", \"obscene\", \"insult\", \"identity_hate\"]\n",
    "from torch.utils.data import DataLoader\n",
    "val = Dataset.from_pandas(val).remove_columns(\"id\")\n",
    "val = val.map(tokenize, batched=True, remove_columns=[\"comment_text\"] + labels)\n",
    "val.set_format(\"torch\", [\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "val_loader = DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febbc06",
   "metadata": {},
   "source": [
    "testing models speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a6e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ FP32 model:  452.98 ms per batch\n",
      "ðŸ”¹ INT8 model:  339.20 ms per batch\n",
      "âš¡ Speedup:     1.34x faster\n"
     ]
    }
   ],
   "source": [
    "# Main model\n",
    "model100.to(\"cpu\").eval()\n",
    "\n",
    "# Quantized model\n",
    "quantized_model.to(\"cpu\").eval()\n",
    "\n",
    "# -----------------------------\n",
    "# Benchmark Function\n",
    "# -----------------------------\n",
    "def benchmark_model(model, dataloader, num_batches=20):\n",
    "    total_time = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            _ = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "        # Timed run\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            start = time.time()\n",
    "            _ = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "            end = time.time()\n",
    "            total_time += (end - start)\n",
    "            n += 1\n",
    "\n",
    "    avg_time_ms = (total_time / n) * 1000\n",
    "    return avg_time_ms\n",
    "\n",
    "# -----------------------------\n",
    "# Run Benchmarks\n",
    "# -----------------------------\n",
    "fp32_time = benchmark_model(model100, val_loader)\n",
    "int8_time = benchmark_model(quantized_model, val_loader)\n",
    "\n",
    "print(f\"ðŸ”¹ FP32 model:  {fp32_time:.2f} ms per batch\")\n",
    "print(f\"ðŸ”¹ INT8 model:  {int8_time:.2f} ms per batch\")\n",
    "print(f\"âš¡ Speedup:     {fp32_time / int8_time:.2f}x faster\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f5ec2f",
   "metadata": {},
   "source": [
    "Now for perfomance comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6b1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multilabel_model(\n",
    "    trainer,\n",
    "    eval_dataset,\n",
    "    label_names,\n",
    "    threshold=0.5,\n",
    "    plot_confusion=True,\n",
    "    normalize_confusion=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs detailed evaluation of a multi-label classification model trained with Hugging Face Trainer.\n",
    "\n",
    "    Args:\n",
    "        trainer (Trainer): Trained Hugging Face Trainer object.\n",
    "        eval_dataset (Dataset): Tokenized evaluation dataset.\n",
    "        label_names (List[str]): List of label column names (e.g., [\"toxic\", ...]).\n",
    "        threshold (float): Threshold for converting sigmoid outputs to binary (default: 0.5).\n",
    "        plot_confusion (bool): Whether to plot confusion matrices.\n",
    "        normalize_confusion (bool): If True, display percentages instead of absolute counts.\n",
    "\n",
    "    Prints:\n",
    "        - Classification report with per-class precision/recall/F1\n",
    "        - Confusion matrices (optionally normalized and visualized)\n",
    "    \"\"\"\n",
    "    # 1. Predict and threshold\n",
    "    predictions_output = trainer.predict(eval_dataset)\n",
    "    logits = predictions_output.predictions\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    y_pred = (probs >= threshold).astype(int)\n",
    "    y_true = predictions_output.label_ids\n",
    "\n",
    "    # 2. Classification report\n",
    "    print(\"\\n Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=label_names,\n",
    "        digits=4\n",
    "    )\n",
    "    print(report)\n",
    "\n",
    "    # 3. Confusion Matrices\n",
    "    print(\"\\n Confusion Matrices:\")\n",
    "    conf_matrices = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    for i, label in enumerate(label_names):\n",
    "        cm = conf_matrices[i]\n",
    "\n",
    "        # Normalize to percentage if requested\n",
    "        if normalize_confusion:\n",
    "            cm_sum = cm.sum()\n",
    "            cm = cm.astype(\"float\") / cm_sum * 100 if cm_sum > 0 else cm\n",
    "\n",
    "        print(f\"\\nConfusion Matrix for '{label}':\")\n",
    "        print(np.round(cm, 2))\n",
    "\n",
    "        if plot_confusion:\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            sns.heatmap(\n",
    "                cm,\n",
    "                annot=True,\n",
    "                fmt=\".1f\" if normalize_confusion else \"d\",\n",
    "                cmap=\"Blues\",\n",
    "                cbar=False\n",
    "            )\n",
    "            plt.title(f\"Confusion Matrix: {label}\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afce61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_accuracy  = evaluate.load(\"accuracy\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall    = evaluate.load(\"recall\")\n",
    "metric_f1        = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))  # sigmoid\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Cast labels to integer type before passing to metrics\n",
    "    labels_int = labels.astype(int)\n",
    "\n",
    "    # Flatten the predictions and references for evaluation metrics\n",
    "    preds_flat = preds.flatten()\n",
    "    labels_int_flat = labels_int.flatten()\n",
    "\n",
    "    # Use the flattened arrays for computing metrics\n",
    "    # Note: Accuracy on flattened arrays represents overall element-wise accuracy.\n",
    "    # For multi-label accuracy, you might want to compute sample-based metrics,\n",
    "    # but for average=\"macro\" precision/recall/f1, flattening is appropriate.\n",
    "    acc  = metric_accuracy.compute(predictions=preds_flat, references=labels_int_flat)\n",
    "    prec = metric_precision.compute(predictions=preds_flat, references=labels_int_flat, average=\"macro\")\n",
    "    rec  = metric_recall.compute(predictions=preds_flat, references=labels_int_flat, average=\"macro\")\n",
    "    f1   = metric_f1.compute(predictions=preds_flat, references=labels_int_flat, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\":  acc[\"accuracy\"],\n",
    "        \"precision\": prec[\"precision\"],\n",
    "        \"recall\":    rec[\"recall\"],\n",
    "        \"f1\":        f1[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7335e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for full model\n",
    "args_1_base = TrainingArguments(\n",
    "    output_dir          = \"./bert_1\",\n",
    "    eval_strategy       = \"epoch\",\n",
    "    save_strategy       = \"no\",\n",
    "    logging_strategy    = \"steps\",\n",
    "    logging_steps       = 50,\n",
    "    learning_rate       = 2e-5,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size  = batch_size,\n",
    "    num_train_epochs    = 10,\n",
    "    weight_decay        = 0.01,\n",
    "    load_best_model_at_end = False,\n",
    "    metric_for_best_model = \"eval_f1\",\n",
    "    save_total_limit    = 2,\n",
    "    seed                = seed,\n",
    "    use_cpu =True,\n",
    "    report_to           = \"none\",  # Disable wandb\n",
    "    fp16                = True # Enable mixed precision training\n",
    ")\n",
    "\n",
    "# Arguments for quantized model\n",
    "args_int8 = TrainingArguments(\n",
    "    output_dir=\"./int8_eval\",\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    use_cpu =True,  # ðŸš¨ dynamic quantized models only work on CPU\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec5e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25960/25960 [00:02<00:00, 10885.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_100 = Dataset.from_pandas(train).remove_columns(\"id\")\n",
    "train_100 = train_100.map(tokenize, batched=True, remove_columns=[\"comment_text\"] + labels)\n",
    "train_100.set_format(\"torch\", [\"input_ids\",\"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9aad60",
   "metadata": {},
   "source": [
    "Loading the trainers objects (we will not train, but they are necessary for evaluating performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "516d161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_int8 = Trainer(\n",
    "    model           = quantized_model,\n",
    "    args            = args_int8,   \n",
    "    eval_dataset    = val,\n",
    "    compute_metrics = compute_metrics \n",
    ")\n",
    "trainer_100 = Trainer(\n",
    "    model           = model100,\n",
    "    args            = args_1_base,\n",
    "    eval_dataset    = val,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1af79a",
   "metadata": {},
   "source": [
    "Running performance evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8119399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluating FP32 (Original) Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic     0.9784    0.9842    0.9813      3034\n",
      " severe_toxic     0.8302    0.8406    0.8354       320\n",
      "      obscene     0.9593    0.9704    0.9648      1653\n",
      "       insult     0.9410    0.9416    0.9413      1559\n",
      "identity_hate     0.9129    0.9198    0.9163       262\n",
      "\n",
      "    micro avg     0.9558    0.9619    0.9588      6828\n",
      "    macro avg     0.9244    0.9313    0.9278      6828\n",
      " weighted avg     0.9558    0.9619    0.9588      6828\n",
      "  samples avg     0.4738    0.4758    0.4717      6828\n",
      "\n",
      "\n",
      " Confusion Matrices:\n",
      "\n",
      "Confusion Matrix for 'toxic':\n",
      "[[52.23  1.02]\n",
      " [ 0.74 46.01]]\n",
      "\n",
      "Confusion Matrix for 'severe_toxic':\n",
      "[[94.22  0.85]\n",
      " [ 0.79  4.14]]\n",
      "\n",
      "Confusion Matrix for 'obscene':\n",
      "[[73.48  1.05]\n",
      " [ 0.76 24.71]]\n",
      "\n",
      "Confusion Matrix for 'insult':\n",
      "[[74.56  1.42]\n",
      " [ 1.4  22.62]]\n",
      "\n",
      "Confusion Matrix for 'identity_hate':\n",
      "[[95.61  0.35]\n",
      " [ 0.32  3.71]]\n",
      "\n",
      "ðŸ“Š Evaluating INT8 (Quantized) Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic     0.9825    0.9268    0.9539      3034\n",
      " severe_toxic     0.9027    0.3187    0.4711       320\n",
      "      obscene     0.9416    0.9564    0.9490      1653\n",
      "       insult     0.9418    0.8922    0.9163      1559\n",
      "identity_hate     0.9667    0.3321    0.4943       262\n",
      "\n",
      "    micro avg     0.9601    0.8748    0.9155      6828\n",
      "    macro avg     0.9471    0.6853    0.7569      6828\n",
      " weighted avg     0.9590    0.8748    0.9039      6828\n",
      "  samples avg     0.4486    0.4303    0.4342      6828\n",
      "\n",
      "\n",
      " Confusion Matrices:\n",
      "\n",
      "Confusion Matrix for 'toxic':\n",
      "[[52.48  0.77]\n",
      " [ 3.42 43.33]]\n",
      "\n",
      "Confusion Matrix for 'severe_toxic':\n",
      "[[94.9   0.17]\n",
      " [ 3.36  1.57]]\n",
      "\n",
      "Confusion Matrix for 'obscene':\n",
      "[[73.02  1.51]\n",
      " [ 1.11 24.36]]\n",
      "\n",
      "Confusion Matrix for 'insult':\n",
      "[[74.65  1.33]\n",
      " [ 2.59 21.43]]\n",
      "\n",
      "Confusion Matrix for 'identity_hate':\n",
      "[[9.592e+01 5.000e-02]\n",
      " [2.700e+00 1.340e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Term_3\\nlp-toxicity-classification-analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Per Label performance\n",
    "print(\"\\nðŸ“Š Evaluating FP32 (Original) Model:\")\n",
    "evaluate_multilabel_model(\n",
    "    trainer=trainer_100,\n",
    "    eval_dataset=val,\n",
    "    label_names=labels,\n",
    "    threshold=0.5,\n",
    "    plot_confusion=False\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluating INT8 (Quantized) Model:\")\n",
    "evaluate_multilabel_model(\n",
    "    trainer=trainer_int8,\n",
    "    eval_dataset=val,\n",
    "    label_names=labels,\n",
    "    threshold=0.5,\n",
    "    plot_confusion=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fd14f",
   "metadata": {},
   "source": [
    "Aggregated Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259f05de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='406' max='406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [406/406 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Results (FP32 - Full Model):\n",
      "  Accuracy:  0.9826\n",
      "  Precision: 0.9728\n",
      "  Recall:    0.9750\n",
      "  F1 Score:  0.9739\n"
     ]
    }
   ],
   "source": [
    "eval_results_100 = trainer_100.evaluate(eval_dataset=val)\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation Results (FP32 - Full Model):\")\n",
    "print(f\"  Accuracy:  {eval_results_100['eval_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {eval_results_100['eval_precision']:.4f}\")\n",
    "print(f\"  Recall:    {eval_results_100['eval_recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {eval_results_100['eval_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f6f4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='406' max='406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [406/406 02:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Results (INT8 - Quantized Model):\n",
      "  Accuracy:  0.9660\n",
      "  Precision: 0.9638\n",
      "  Recall:    0.9326\n",
      "  F1 Score:  0.9471\n"
     ]
    }
   ],
   "source": [
    "eval_results_int8 = trainer_int8.evaluate(eval_dataset=val)\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation Results (INT8 - Quantized Model):\")\n",
    "print(f\"  Accuracy:  {eval_results_int8['eval_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {eval_results_int8['eval_precision']:.4f}\")\n",
    "print(f\"  Recall:    {eval_results_int8['eval_recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {eval_results_int8['eval_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415f988",
   "metadata": {},
   "source": [
    "## C)  Analysis and Improvements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b4b9b",
   "metadata": {},
   "source": [
    "Overall, the performance loss from quantization is minimal, while achieving a 30â€“40% speedup in inference time on CPU. However, it's worth noting that recall dropped significantly for the severe_toxic and identity_hate labels, even though precision remained relatively strong. This likely stems from the fact that these classes are underrepresented in the dataset, comprising only 5.00% and 4.33% of the samples, respectively. As a result, the simplification introduced by quantization may have led to the model losing some of the finer-grained patterns needed to correctly identify these rare cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076805e",
   "metadata": {},
   "source": [
    "We will analyze some examples for these two classes. Specifically, when the full model made an accurate prediction but the Quantized model did not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f08b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6490/6490 [16:04<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set rare labels to inspect\n",
    "rare_labels = [\"severe_toxic\", \"identity_hate\"]\n",
    "rare_indices = [labels.index(lbl) for lbl in rare_labels]\n",
    "\n",
    "# Convert val to a list of dictionaries\n",
    "val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_list = [val[i] for i in range(len(val))]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Run inference on both models\n",
    "model100.eval().to(\"cpu\")\n",
    "quantized_model.eval().to(\"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, sample in tqdm(enumerate(val_list), total=len(val_list)):\n",
    "        input_ids = sample[\"input_ids\"].unsqueeze(0)\n",
    "        attention_mask = sample[\"attention_mask\"].unsqueeze(0)\n",
    "        true_labels = sample[\"labels\"].numpy()\n",
    "\n",
    "        # Get predictions\n",
    "        logits_fp32 = model100(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "        logits_int8 = quantized_model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        probs_fp32 = torch.sigmoid(logits_fp32).squeeze().numpy()\n",
    "        probs_int8 = torch.sigmoid(logits_int8).squeeze().numpy()\n",
    "\n",
    "        preds_fp32 = (probs_fp32 >= 0.5).astype(int)\n",
    "        preds_int8 = (probs_int8 >= 0.5).astype(int)\n",
    "\n",
    "        # Check for rare label hits\n",
    "        for idx in rare_indices:\n",
    "            if true_labels[idx] == 1 and preds_fp32[idx] == 1 and preds_int8[idx] == 0:\n",
    "                results.append({\n",
    "                    \"id\": i,  # ðŸ”¥ Now includes row index\n",
    "                    \"label\": labels[idx],\n",
    "                    \"true\": int(true_labels[idx]),\n",
    "                    \"fp32_pred\": int(preds_fp32[idx]),\n",
    "                    \"int8_pred\": int(preds_int8[idx]),\n",
    "                    \"fp32_prob\": float(probs_fp32[idx]),\n",
    "                    \"int8_prob\": float(probs_int8[idx])\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00d241f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame(results)\n",
    "# Step 3: Merge comment_text into df_diff using 'id'\n",
    "val_metadata.index.name = \"id\"\n",
    "# Merge using df_diff[\"id\"] and val_metadata index\n",
    "df_diff = df_diff.merge(val_metadata, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35b553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by label and compute average probability per model\n",
    "avg_probs = df_diff.groupby(\"label\")[[\"fp32_prob\", \"int8_prob\"]].mean().reset_index()\n",
    "\n",
    "# Melt for plotting\n",
    "avg_probs_melted = avg_probs.melt(\n",
    "    id_vars=\"label\",\n",
    "    value_vars=[\"fp32_prob\", \"int8_prob\"],\n",
    "    var_name=\"model\",\n",
    "    value_name=\"avg_probability\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=avg_probs_melted,\n",
    "    x=\"label\",\n",
    "    y=\"avg_probability\",\n",
    "    hue=\"model\"\n",
    ")\n",
    "\n",
    "plt.title(\"Avg Predicted Probability per Label in Missed int8 Predictions\", fontsize=14)\n",
    "plt.ylabel(\"Average Probability\", fontsize=12)\n",
    "plt.xlabel(\"Label\", fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b9abc",
   "metadata": {},
   "source": [
    "## Severe toxic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6772541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                      comment_text  fp32_prob  int8_prob  prob_diff\n",
      "                                                                                                                                                                        Dumb Liberals \\n\\nLiberals suck.  I will beat you at tanks anytime you swastika wearing freak.  Sieg Heil.   0.985693   0.007503   0.978190\n",
      "                                                        Thanks for being late to the party \\n\\nbut I have added no new articles since yesterday.  While you have all been very impolite and overly protective, I have lost interest in torturing you, so you can go fuck yourself.   0.977846   0.015514   0.962333\n",
      "                                                                                                                               wateva minga mc donalds worker\\nu r a fuckin paedofile\\nleave ant and dec alone \\njust cause ur not famous\\nu fuckin ugly bitch fuck ur hole family   0.947888   0.002346   0.945542\n",
      "Fuck you all. This site is full of stuck up cunts, who for some unknown reason think being a part of wikipedia promotes them to President of the cyberspace. Sad pricks, go fuck yourselves. I won't be returning to this site. So off you all go to self congratulate yourselves.   0.975819   0.036370   0.939450\n",
      "                                 i DONT KNOW HOW THIS THING WORKS. BUT I'LL TELL YOU THIS. VERTIGO ACID. CALL ME FAMILY FLUFF. STOP THREATENING ME YOU TIGHT DRY LITTLE PUSSY. I OWN THIS FING CITY. AND I'LL OWN YOUR FING PUNK ASS IF YOU DONT STAY OUT OF MY BUSINESS. CAPICHE?   0.985651   0.057037   0.928613\n"
     ]
    }
   ],
   "source": [
    "# Filter only for 'severe_toxic' samples\n",
    "severe_df = df_diff[df_diff[\"label\"] == \"severe_toxic\"].copy()\n",
    "\n",
    "# Compute absolute difference in predicted probabilities\n",
    "severe_df[\"prob_diff\"] = (severe_df[\"fp32_prob\"] - severe_df[\"int8_prob\"]).abs()\n",
    "\n",
    "# Sort by difference and take top 2\n",
    "top_diff = severe_df.sort_values(by=\"prob_diff\", ascending=False).head(5)\n",
    "\n",
    "# Display relevant info\n",
    "cols_to_show = [\"comment_text\", \"fp32_prob\", \"int8_prob\", \"prob_diff\"]\n",
    "print(top_diff[cols_to_show].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bac693",
   "metadata": {},
   "source": [
    "The quantized model struggles to accurately identify uncommon or highly toxic language. This is likely because quantization reduces the modelâ€™s ability to preserve subtle distinctions that enable the full-precision model to classify these cases correctly. For example comments like:\n",
    "\n",
    "\"Dumb Liberals ... swastika wearing freak. Sieg Heil.\"\n",
    "\n",
    "\"i DONT KNOW HOW THIS THING WORKS... I OWN THIS FING CITY...\"\n",
    "\n",
    "contain less common or very informal/slang expressions.\n",
    "\n",
    "Quantized models often generalize less well on out-of-distribution or unusual inputs due to precision loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccd217",
   "metadata": {},
   "source": [
    "## Identity hate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b567b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 comment_text  fp32_prob  int8_prob  prob_diff\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                sabu is a violent piece of crap \\n\\ndis guy is so violent.he hits people with steel chairs,triple jump moonsaults ppl thru tables.he coud put som1 thru a burning table which could kill them.he was taughtby his uncle,and he is from bombay,india.\\nuser:dark-hooded smoker   0.994267   0.001979   0.992288\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ur so immature fr3nzi3,im 17 and ur not evn debating.ur a 6 year old baby and im like an adult,nobody likes you.anyway,everybody doesn't like any fat assholes like u.grown-ups fight like a man,i fight using words like swearin' like eminem dos in is songs.u don't evn have a brain,shit wat a crazy guy.\\nuser:dark-hooded smoker   0.991873   0.011275   0.980598\n",
      "\"\\n\\nLOL, haha, you loser Wobbs, yeah maybe I am Epf......NOT. Although he shares some views with me on race and other things, hes some dumb Italian-British mut from Canada that actually annoys me. I have used other accounts on here, but with other anon. accounts, not as a registered user (which is allowed by Wikipedia since IP #'s change all the time). Hahaha, Wobbs, you are a fool, especially with how you place so much emphasis on those books recently released by Sykes, etc. which are minority opinions in the world of population geneticists and other researcher. For your information, Racial Reality isn't a \"\"neo-nazi\"\" site you anarchist loser with no hope because your life is meaningless and you don't know ANYTHING on what you read about with these issues. RR is a neutral point of view that seeks to refute neo-nazi, white supremacists, multi-racial, race-denier, assimilationist, biased opinions that influence works including the authors of those books you mentioned. Stick to being a pathetic lab assistant and get a life you tool and stop vandalizing pages and makin edits to suit your twisted opinons you fool. Hahaha, wow, do u accuse 'sock pupety\"\" of everyone who gets under you skin you douchebag ???  23:37, 5 January 2007 (UTC\\n\\n - Oh and Veritas you dumb fool, I find it insulting you compare my language to Epf's when at least I know what Im talkin about on this stuff while hes just some pussy who confuses people and his arguments cant comapare at all to the brilliant logic of mine. Hahah, you and Wobbs are the worst contributors to this WIkipedia thing, don't ever use this, no one wants you here !! Hahaha !!! \"   0.969461   0.001824   0.967638\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Dictionaries\\n\\nHow dare you call my contribution spam!!! I am a Kurd and I made a lsit of kurdish dictionaries. you bloody turkish nationalist and atoricity commiting bone breaking Nazi. watch out folk this slimy Turk is trying to censor the internet this is not undemocratic Turkey here, no prison cells in wikipedia you stupid Turk! And you buggers want membership to the EEC   0.992165   0.034858   0.957307\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Listen you piece of shit , pencil necked twerp that you are. Nowhere did I make any further attacks to anyone. How about you get a fuckin life rather than getting a little stiffy from banning people. I couldnt give a slight fuck about your lame arse wiki. Its bullshit anyways. You people just like reading your own crap. Brisbane is a fuckin small place and google is a great tool. \\n\\nYet another christian piece of shit. I shit on your god you little fuck.   0.959242   0.003523   0.955719\n"
     ]
    }
   ],
   "source": [
    "# Filter only for 'identity_hate' samples\n",
    "severe_df = df_diff[df_diff[\"label\"] == \"identity_hate\"].copy()\n",
    "\n",
    "# Compute absolute difference in predicted probabilities\n",
    "severe_df[\"prob_diff\"] = (severe_df[\"fp32_prob\"] - severe_df[\"int8_prob\"]).abs()\n",
    "\n",
    "# Sort by difference and take top 2\n",
    "top_diff = severe_df.sort_values(by=\"prob_diff\", ascending=False).head(5)\n",
    "\n",
    "# Display relevant info\n",
    "cols_to_show = [\"comment_text\", \"fp32_prob\", \"int8_prob\", \"prob_diff\"]\n",
    "print(top_diff[cols_to_show].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a34350",
   "metadata": {},
   "source": [
    "For identity hate a similar thing is happening, these comments are highly charged with specific language against ethnic or religious groups (e.g., \"Kurd, \"Turkish nationalist,\" \"christian piece of shit\"). The full model picks up these signals confidently, while quantization likely blunts or loses sensitivity to the key hateful keywords or phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9349b",
   "metadata": {},
   "source": [
    "## Suggested improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d58a04",
   "metadata": {},
   "source": [
    "1. Quantization-Aware Training (QAT):\n",
    "Instead of applying quantization after training, QAT incorporates quantization effects directly during training. This helps the model learn representations that are robust to reduced precision, allowing it to maintain better accuracyâ€”especially on subtle or rare toxic cases that suffer most from post-training quantization.\n",
    "\n",
    "2. Advanced Distillation Methods:\n",
    "In this work, we did not apply knowledge distillation; however, it represents a promising avenue for improvement. Distillation can be enhanced by transferring not only the final outputs but also intermediate representations such as hidden layer activations or attention maps. Using a larger, full-precision teacher model to guide a student model can help the student capture nuanced patterns learned by the teacher. This deeper mimicry might lead to improved classification performance, especially on complex or subtle examples.\n",
    "\n",
    "3. Hybrid Quantization Strategies:\n",
    "In our approach, we applied quantization selectivelyâ€”only on the linear layers of the modelâ€”while leaving other components in full precision. Although this targeted quantization provides computational speedup, it still led to some degradation in performance. As an alternative, exploring mixed-precision quantization, where critical layers such as embeddings or attention modules are kept in higher precision (e.g., FP16 or FP32) while less sensitive layers are quantized, could better preserve accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
